/* IMPORTANT
 * This snapshot file is auto-generated, but designed for humans.
 * It should be checked into source control and tracked carefully.
 * Re-generate by setting TAP_SNAPSHOT=1 and running tests.
 * Make sure to inspect the output below.  Do not ignore changes!
 */
'use strict'
exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in danish > Should tokenize and stem correctly in danish-O1 1`] = `
Array [
  "sovn",
  "svar",
  "ting",
  "prover",
  "mislykk",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in danish > Should tokenize and stem correctly in danish-O2 1`] = `
Array [
  "bagt",
  "smakag",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in dutch > Should tokenize and stem correctly in dutch-O1 1`] = `
Array [
  "klein",
  "koeien",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in dutch > Should tokenize and stem correctly in dutch-O2 1`] = `
Array [
  "taarten",
  "gemaakt",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english > Should tokenize and stem correctly in english-O1 1`] = `
Array [
  "the",
  "quick",
  "brown",
  "fox",
  "jump",
  "over",
  "lazi",
  "dog",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english > Should tokenize and stem correctly in english-O2 1`] = `
Array [
  "i",
  "bake",
  "some",
  "cake",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english and allow duplicates > Should tokenize and stem correctly in english and allow duplicates-O1 1`] = `
Array [
  "thi",
  "is",
  "a",
  "test",
  "with",
  "test",
  "duplic",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english and allow duplicates > Should tokenize and stem correctly in english and allow duplicates-O2 1`] = `
Array [
  "it'",
  "aliv",
  "it'",
  "aliv",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in finnish > Should tokenize and stem correctly in finnish-O1 1`] = `
Array [
  "uni",
  "vaik",
  "asi",
  "test",
  "epaonnistuvat",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in finnish > Should tokenize and stem correctly in finnish-O2 1`] = `
Array [
  "leivoin",
  "kekseja",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in french > Should tokenize and stem correctly in french-O1 1`] = `
Array [
  "voyon",
  "temp",
  "fait",
  "dehor",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in french > Should tokenize and stem correctly in french-O2 1`] = `
Array [
  "fait",
  "gateau",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in german > Should tokenize and stem correctly in german-O1 1`] = `
Array [
  "schlaf",
  "hart",
  "sach",
  "test",
  "fehlschlagen",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in german > Should tokenize and stem correctly in german-O2 1`] = `
Array [
  "paar",
  "keks",
  "gebacken",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in italian > Should tokenize and stem correctly in italian-O1 1`] = `
Array [
  "cucinato",
  "tort",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in italian > Should tokenize and stem correctly in italian-O2 1`] = `
Array [
  "dormir",
  "cos",
  "difficil",
  "quando",
  "test",
  "passano",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in norwegian > Should tokenize and stem correctly in norwegian-O1 1`] = `
Array [
  "kokt",
  "kak",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in norwegian > Should tokenize and stem correctly in norwegian-O2 1`] = `
Array [
  "sov",
  "vanskelig",
  "ting",
  "testen",
  "mislykk",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in portuguese > Should tokenize and stem correctly in portuguese-O1 1`] = `
Array [
  "cozinhei",
  "algun",
  "bolos",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in portuguese > Should tokenize and stem correctly in portuguese-O2 1`] = `
Array [
  "dorm",
  "e",
  "cois",
  "dificil",
  "test",
  "falham",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in russian > Should tokenize and stem correctly in russian-O1 1`] = `
Array [
  "приготовила",
  "пирожные",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in russian > Should tokenize and stem correctly in russian-O2 1`] = `
Array [
  "спать",
  "трудно",
  "тесты",
  "срабатывают",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in spanish > Should tokenize and stem correctly in spanish-O1 1`] = `
Array [
  "cocin",
  "pastel",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in spanish > Should tokenize and stem correctly in spanish-O2 1`] = `
Array [
  "dorm",
  "dificil",
  "prueb",
  "fallan",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in swedish > Should tokenize and stem correctly in swedish-O1 1`] = `
Array [
  "lagad",
  "kakor",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in swedish > Should tokenize and stem correctly in swedish-O2 1`] = `
Array [
  "sov",
  "svar",
  "sak",
  "testern",
  "misslyck",
]
`
